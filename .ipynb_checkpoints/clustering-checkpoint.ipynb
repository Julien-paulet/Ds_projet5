{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import pi\n",
    "from sklearn import preprocessing, decomposition\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prepData():\n",
    "    def centrageReduction(data):\n",
    "        X = data.values\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X_scaled = std_scale.transform(X)\n",
    "        return X_scaled\n",
    "        \n",
    "    def acp():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clustering():\n",
    "\n",
    "    def silhouette(data, X_scaled, min_clust, max_clust, random_s=42, acp=False, *acp_data):\n",
    "        \"\"\"Fonction qui calcul le coefficient de silouhette pour différents nombres de\n",
    "        Clusters. Renvoie un dataframe avec le coef pour chaque nombre de Clusters \\n\n",
    "        Le df est classé de la plus grande valeur du coef à la plus petite\"\"\"\n",
    "        \n",
    "        #On fixe le random \n",
    "        np.random.seed(random_s)\n",
    "\n",
    "        #ACP si paramètre à True\n",
    "        if acp == True:\n",
    "            X_scaled = acp_data\n",
    "            #Partie à faire, il faut penser à remettre les données transfo par la suite\n",
    "            #Pour la compréhension des Clusters\n",
    "\n",
    "        #Init silouhette list\n",
    "        silouhette = []\n",
    "        #init index list\n",
    "        index_ = []\n",
    "        for i in range(min_clust,max_clust+1):\n",
    "            index_.append(i)\n",
    "            #Clustering :\n",
    "            kmeans = KMeans(n_clusters=i, random_state=random_s).fit(X_scaled)\n",
    "            #Calcul coef de silouhette\n",
    "            silhouette_avg = silhouette_score(data, kmeans.labels_)\n",
    "            silouhette.append(silhouette_avg) \n",
    "            \n",
    "        #Création d'un DataFrame\n",
    "        silouhette_coef = pd.DataFrame(silouhette, index=index_, columns=['coef'])\n",
    "        silouhette_coef = silouhette_coef.sort_values(by='coef', ascending=False).reset_index() \n",
    "        \n",
    "        #Plot les coef en fonction des clusters\n",
    "        plt.plot(silouhette_coef['coef'], silouhette_coef['index'])\n",
    "        plt.show()\n",
    "        \n",
    "        return silouhette_coef\n",
    "    \n",
    "    \n",
    "    def makeClustering(data, X_scaled, coef, random_s=42, algo='kmeans', epsilon=0.5):\n",
    "\n",
    "        \"\"\"Fonction de clustering, selon l'algo voulu par l'utilisateur. \\n\n",
    "        Disponible : Kmeans, Hierarchique, db_scan\"\"\"\n",
    "        \n",
    "        \"\"\"Ici coef représente le coefficient nombre de clusters pour kmeans \n",
    "        (ou le df généré) par la fonction silhouette ; \\n\n",
    "        Mais aussi le min_sample pour Db_scan. \\n\n",
    "        Un seul algorithme peut être utilisé à la fois.\"\"\"\n",
    "        \n",
    "        #On fixe le random\n",
    "        np.random.seed(random_s)\n",
    "        \n",
    "        #On check si la variable algo est bien dans la liste disponible\n",
    "        algos = ['kmeans', 'hierarchical', 'db_scan']\n",
    "        if algo not in algos:\n",
    "            raise ValueError(\"Tu n'as pas rentré le bon algorithme. Voici la liste dispo: %s\" % algos)\n",
    "        \n",
    "        #Si l'algorithme choisi est kmeans :\n",
    "        if algo == 'kmeans':\n",
    "            try : \n",
    "                clust = coef.iloc[0,0] #Si le nbr clust vient de la func précédente\n",
    "            except:\n",
    "                clust = coef #Si le nombre de cluster vient de l'utilisateur\n",
    "                \n",
    "            data_clust = clustering.kmeansClustering(data, X_scaled, clust, random_s)\n",
    "            \n",
    "        #Si c'est du clustering hiérarchique   \n",
    "        if algo == 'hierarchical':\n",
    "            print('Still in build, use kmeans or db_scan for now')\n",
    "        \n",
    "        #Si c'est db_scan\n",
    "        if algo == 'db_scan':        \n",
    "            data_clust = clustering.db_scanClustering(data, X_scaled, random_s, epsilon, coef, n_jobs)\n",
    "            \n",
    "        return data_clust\n",
    "    \n",
    "    \n",
    "    def grouping(data_clust):\n",
    "\n",
    "        data_grouped = data_clust.groupby('Clusters').mean()\n",
    "        return data_grouped\n",
    "    \n",
    "    def kmeansClustering(data, X_scaled, clust, random_s):\n",
    "        \n",
    "        np.random.seed(random_s)\n",
    "            \n",
    "        #Clustering avec le bon nombre de clusters\n",
    "        kmeans = KMeans(n_clusters=clust, random_state=random_s).fit(X_scaled)\n",
    "        kmeans = pd.DataFrame(kmeans.labels_, index = data.index, columns=[\"Clusters\"])\n",
    "\n",
    "        #On merge avec nos données \n",
    "        data_clust = pd.merge(data, kmeans, left_index=True, right_index=True, how='left')\n",
    "        \n",
    "        return data_clust\n",
    "    \n",
    "    def db_scanClustering(data, X_scaled, random_s, epsilon, mini_sample, n_jobs_):\n",
    "        \n",
    "        np.random.seed(random_s)\n",
    "        \n",
    "        #On entraine l'algorithme\n",
    "        db = DBSCAN(eps=epsilon, min_samples=mini_sample, n_jobs=n_jobs_).fit(X_scaled)\n",
    "        \n",
    "        #On récupère chaque Clusters\n",
    "        labels = pd.DataFrame(db.labels_, index = data.index, columns=[\"Clusters\"])\n",
    "        \n",
    "        #On merge sur nos données\n",
    "        data_clust = pd.merge(data, labels, left_index=True, right_index=True, how='left')\n",
    "        \n",
    "        return data_clust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class plotClustering():\n",
    "    \n",
    "    def plotPairplot(data_clust, save=False, *path):\n",
    "        \"\"\"Fonction permettant la création de Pairplot\"\"\"\n",
    "\n",
    "        warnings.filterwarnings(\"ignore\") #Ignore les messages warnings\n",
    "\n",
    "        #Initialisation du pairplot\n",
    "        sns.pairplot(data_clust, hue=\"Clusters\") \n",
    "        \n",
    "        if save == True :\n",
    "            try:\n",
    "                plt.savefig(path + \"Pairplot.png\")\n",
    "            except:\n",
    "                print('Missing the path for saving')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def plotBoxplot(data_clust, save=False, *path):\n",
    "        \"\"\"Fonction permettant la création de Boxplot\"\"\"\n",
    "\n",
    "        \n",
    "        data_ = data_clust.reset_index()\n",
    "\n",
    "        sous_echantillon = data_.copy()\n",
    "        modalites = sous_echantillon[\"Clusters\"].unique()\n",
    "\n",
    "        for var in data_clust.columns:\n",
    "            X = \"Clusters\" # qualitative\n",
    "            Y = var # quantitative\n",
    "\n",
    "            groupes = []\n",
    "            for m in modalites:\n",
    "                groupes.append(sous_echantillon[sous_echantillon[X]==m][Y].dropna())\n",
    "\n",
    "            medianprops = {'color':\"black\"}\n",
    "            meanprops = {'marker':'o', 'markeredgecolor':'black',\n",
    "                        'markerfacecolor':'firebrick'}\n",
    "\n",
    "            plt.figure(figsize=[8,20])\n",
    "            plt.boxplot(groupes, labels=modalites, showfliers=False, medianprops=medianprops, \n",
    "                        vert=False, patch_artist=True, showmeans=True, meanprops=meanprops)\n",
    "            plt.title(\"Boxplot\")\n",
    "            plt.xlabel(var)\n",
    "            plt.ylabel(\"Clusters\")\n",
    "\n",
    "            #Si save = True alors on enregistre\n",
    "            if save == True :\n",
    "                try:\n",
    "                    plt.savefig(path + \"boxplot\" + var + \".png\")\n",
    "                except:\n",
    "                    print('Missing the path for saving')\n",
    "\n",
    "            #On affiche les plots\n",
    "            plt.show()\n",
    "    \n",
    "    def plotRadarplot(data_grouped, save=False, *path):\n",
    "        #On récupère le nom des features\n",
    "        variables = data_grouped.columns\n",
    "        \n",
    "        #On récupère le range de chaque variable\n",
    "        ranges = findRanges(data_grouped)\n",
    "        \n",
    "        #On plot chaque cluster sur un radar différent\n",
    "        for i in range(0, len(data_grouped)):\n",
    "            #Init la figure\n",
    "            fig1 = plt.figure(figsize=(6, 6))\n",
    "            #Init le radar\n",
    "            radar = ComplexRadar(fig1, variables, ranges)\n",
    "            #Mise en place des valeurs sur le radar\n",
    "            radar.plot(data_grouped.loc[i,:], ranges) #Bande orange bizarre\n",
    "            #Fill le radar (pour plus de clarté)\n",
    "            radar.fill(data_grouped.loc[i,:], alpha=0.2)\n",
    "            if save==True:\n",
    "                try:\n",
    "                    plt.savefig(path + \"radar\" + data_grouped.loc[i,:] + \".png\")\n",
    "                except:\n",
    "                    print('Missing the path for saving')\n",
    "                    \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base du code trouvées sur <a>https://datascience.stackexchange.com/questions/6084/how-do-i-create-a-complex-radar-chart</a>\n",
    "<br/>\n",
    "Puis modifié par mes soins pour correspondre aux données d'entrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRanges(data_grouped):\n",
    "    ranges = []\n",
    "    for i in data_grouped.columns:\n",
    "        theRange = (data_grouped[i].min(), data_grouped[i].max())\n",
    "        ranges.append(theRange)\n",
    "    return ranges\n",
    "\n",
    "def _invert(x, limits):\n",
    "    \"\"\"inverts a value x on a scale from\n",
    "    limits[0] to limits[1]\"\"\"\n",
    "    return limits[1] - (x - limits[0])\n",
    "\n",
    "def _scale_data(data_grouped, ranges):\n",
    "    \"\"\"scales data[1:] to ranges[0],\n",
    "    inverts if the scale is reversed\"\"\"\n",
    "\n",
    "    x1, x2 = ranges[0]\n",
    "    d = data_grouped[0]\n",
    "\n",
    "    if x1 > x2:\n",
    "        d = _invert(d, (x1, x2))\n",
    "        x1, x2 = x2, x1\n",
    "\n",
    "    sdata = [d]\n",
    "\n",
    "    for d, (y1, y2) in zip(data_grouped[1:], ranges[1:]):\n",
    "        if y1 > y2:\n",
    "            d = _invert(d, (y1, y2))\n",
    "            y1, y2 = y2, y1\n",
    "\n",
    "        sdata.append((d-y1) / (y2-y1) * (x2 - x1) + x1)\n",
    "\n",
    "    return sdata\n",
    "\n",
    "def set_rgrids(self, radii, labels=None, angle=None, fmt=None,\n",
    "               **kwargs):\n",
    "    \"\"\"\n",
    "    Set the radial locations and labels of the *r* grids.\n",
    "    The labels will appear at radial distances *radii* at the\n",
    "    given *angle* in degrees.\n",
    "    *labels*, if not None, is a ``len(radii)`` list of strings of the\n",
    "    labels to use at each radius.\n",
    "    If *labels* is None, the built-in formatter will be used.\n",
    "    Return value is a list of tuples (*line*, *label*), where\n",
    "    *line* is :class:`~matplotlib.lines.Line2D` instances and the\n",
    "    *label* is :class:`~matplotlib.text.Text` instances.\n",
    "    kwargs are optional text properties for the labels:\n",
    "    %(Text)s\n",
    "    ACCEPTS: sequence of floats\n",
    "    \"\"\"\n",
    "    # Make sure we take into account unitized data\n",
    "    radii = self.convert_xunits(radii)\n",
    "    radii = np.asarray(radii)\n",
    "    rmin = radii.min()\n",
    "    # if rmin <= 0:\n",
    "    #     raise ValueError('radial grids must be strictly positive')\n",
    "\n",
    "    self.set_yticks(radii)\n",
    "    if labels is not None:\n",
    "        self.set_yticklabels(labels)\n",
    "    elif fmt is not None:\n",
    "        self.yaxis.set_major_formatter(FormatStrFormatter(fmt))\n",
    "    if angle is None:\n",
    "        angle = self.get_rlabel_position()\n",
    "    self.set_rlabel_position(angle)\n",
    "    for t in self.yaxis.get_ticklabels():\n",
    "        t.update(kwargs)\n",
    "    return self.yaxis.get_gridlines(), self.yaxis.get_ticklabels()\n",
    "\n",
    "class ComplexRadar():\n",
    "    def __init__(self, fig, variables, ranges, n_ordinate_levels=6):\n",
    "        angles = np.arange(0, 360, 360./len(variables))\n",
    "\n",
    "        axes = [fig.add_axes([0.1,0.1,0.9,0.9],polar=True,\n",
    "                label = \"axes{}\".format(i)) \n",
    "                for i in range(len(variables))]\n",
    "        l, text = axes[0].set_thetagrids(angles, \n",
    "                                         labels=variables)\n",
    "        [txt.set_rotation(angle-90) for txt, angle \n",
    "             in zip(text, angles)]\n",
    "        for ax in axes[1:]:\n",
    "            ax.patch.set_visible(False)\n",
    "            ax.grid(\"off\")\n",
    "            ax.xaxis.set_visible(False)\n",
    "        for i, ax in enumerate(axes):\n",
    "            grid = np.linspace(*ranges[i], \n",
    "                               num=n_ordinate_levels)\n",
    "            gridlabel = [\"{}\".format(round(x,2)) \n",
    "                         for x in grid]\n",
    "            if ranges[i][0] > ranges[i][1]:\n",
    "                grid = grid[::-1] # hack to invert grid\n",
    "                          # gridlabels aren't reversed\n",
    "            gridlabel[0] = \"\" # clean up origin\n",
    "            # ax.set_rgrids(grid, labels=gridlabel, angle=angles[i])\n",
    "            set_rgrids(ax, grid, labels=gridlabel, angle=angles[i])\n",
    "            #ax.spines[\"polar\"].set_visible(False)\n",
    "            ax.set_ylim(*ranges[i])\n",
    "        # variables for plotting\n",
    "        self.angle = np.deg2rad(np.r_[angles, angles[0]])\n",
    "        self.ranges = ranges\n",
    "        self.ax = axes[0]\n",
    "    def plot(self, data_grouped, *args, **kw):\n",
    "        sdata = _scale_data(data_grouped, self.ranges)\n",
    "        self.ax.plot(self.angle, np.r_[sdata, sdata[0]], *args, **kw)\n",
    "    def fill(self, data_grouped, *args, **kw):\n",
    "        sdata = _scale_data(data_grouped, self.ranges)\n",
    "        self.ax.fill(self.angle, np.r_[sdata, sdata[0]], *args, **kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe Clustering complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClustEmAll():\n",
    "    def allClustering(data, min_clust, max_clust, random_s=42, algo='kmeans',\n",
    "                      acp=False, save=False, *path):\n",
    "        \"\"\"Fonction permettant un Clustering complet avec plot des résultats\"\"\"\n",
    "        \n",
    "        #Initialisation des variables\n",
    "        self.data = data\n",
    "        self.min_clust = min_clust\n",
    "        self.max_clust = max_clust\n",
    "        self.random_s = random_s\n",
    "        self.algo = algo\n",
    "        self.acp = acp\n",
    "        self.save = save\n",
    "        if path:\n",
    "            self.path = path\n",
    "        \n",
    "        #On fixe le random\n",
    "        np.random.seed(random_s)\n",
    "        \n",
    "        #---Préparation des données\n",
    "        #On centre et on réduit\n",
    "        X_scaled = prepData.centrageReduction(data)\n",
    "        \n",
    "        #On fait une ACP si demandée\n",
    "        if acp==True:\n",
    "            prepData.acp(data, X_scaled) \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        #---Clustering\n",
    "        #Calcul silhouette\n",
    "        silouhette_coef = clustering.silhouette(self.data, self.min_clust, \n",
    "                                                self.max_clust, self.random_s, \n",
    "                                                self.acp)\n",
    "        #Clustering\n",
    "        data_clust = clustering.makeClustering(self.data, X_scaled, silouhette_coef, \n",
    "                                         self.random_s, self.algo)\n",
    "        \n",
    "        #Grouping\n",
    "        data_grouped = clustering.grouping(data_clust)\n",
    "        \n",
    "        #---Plot\n",
    "        #Pairplot\n",
    "        plotClustering.plotPairplot(data_clust, self.save) #Penser à rajouter le path\n",
    "        #Boxplot\n",
    "        plotClustering.plotBoxplot(data_clust, self.save)\n",
    "        #Radar\n",
    "        plotClustering.plotRadarplot(data_grouped, self.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
